---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "SDS348"
date: ''
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
---
Qinglong Yang qy929
```{r setup, include=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

knitr::opts_chunk$set(echo = TRUE, eval = TRUE,fig.align="center",warning=FALSE,message=FALSE,fig.width=8, fig.height=5, linewidth=60)
options(tibble.width = 100,width = 100)
library(tidyverse)
```

## Introduction
The  dataset used for this project was retreived from vincentarelbundock.github.io/Rdatasets/datasets.html. It includes 1174 observations and contains variables that are possibly linked to violent crime rates. These variables include violent (the violent crime rate), murder (the murder rate), prisoners (the number of incarcerated), afam (percent of state population that is African-American, ages 10 to 64), cauc (percent of state population that is Caucasian, ages 10 to 64), male (the percent of the states population that is a male between the ages of 10 to 29), income (the real per capita income), and law (whether or not the state has a gun carry law).

```{r}
library(tidyverse)
library(readr)
guns <- read_csv("Gunssds.csv")
head(guns)


#Manova test
man1<-manova(cbind(violent,murder,prisoners,afam,cauc,male)~law,data=guns)
summary(man1,tol=0)

#Anova test
summary(aov(guns$violent~guns$law))
summary(aov(guns$murder~guns$law))
summary(aov(guns$prisoners~guns$law))
summary(aov(guns$afam~guns$law))
summary(aov(guns$cauc~guns$law))
summary(aov(guns$male~guns$law))
summary(aov(guns$income~guns$law))
0.05/8 #(1 manova,7 anova)
#Calculating probability of a type 1 error
1-(0.95)^8
```

First off I conducted a one-way manova test. This was conducted in order to see whether gun laws have any effect on 6 unique dependent variables which include murder,prisoners,afam,cauc,male, and income. The number of unique observations in each group was far greater than 25. As a result, it can be assumed that the variables should have some kind of normal distribution. Not only that, it can also be assumed that the samples were done at random and all the observations were made independent of each other. Also, we can assume that there are no unusual outliers as the dataset was taken with several datapoints throughout the US. Lastly, it is very unlikely that the dependent variables were not correlated as they logically seem to be related in some way to each other as a higher murder rate normally brings a higher violence rate and higher population numbers will likely increase crime regardless of race. The results obtained from the manova test give evidence that at least one of the mean values of the dependent variables differ very significantly from the violence rate (p=<2.2e-16) even after the bonferri adjustment is made as p remains much significantly larger than 0.005. After this was done, Post-anova tests were conducted in order to see which of the dependent variables are significant with respect to the violent crime rate. After the Bonferri correction it was found that the variables violent, murder, afam, cauc, and male were still statistically significant. Pairwise t-tests were not performed as the categorical variable law is binary (yes or no) so it would be redundant to perform a pairwise test on it. A total of 8 tests were performed, and the probability of having a type 1 error was calculated to be 33.66%.

## Randomization Test
```{r}
#Test statistic calculation
yes<-guns%>%filter(law=="yes")
no<-guns%>%filter(law=="no")
mean(no$violent)-mean(yes$violent)
#Randomizing data
rand_dist<-vector()
for(i in 1:5000){
new<-data.frame(violent=sample(guns$violent),condition=guns$law)
rand_dist[i]<-mean(new[new$condition=="yes",]$violent)-
mean(new[new$condition=="no",]$violent)}
hist(rand_dist,main="",ylab="");abline(v=-161.1868,col="red")
#Calculating P-value
mean(rand_dist>161.1868)*2
```
The test's null hypothesis states that the difference between mean violent crime in areas with gun laws and areas without gun laws is zero or insignificant. THe alternative hypothesis is that there is a significant difference. The mean difference between the samples of violent crime rates between the two groups yielded a value of 161.1868. After conducting the test on this value, it was deemed that this value was significant as the p-value was found to be 0. This is further evidenced by the fact that the red line does not even show up on the histogram. As a result, it is reasonable to reject the null hypothesis and accept the alternative hypothesis. Therefore we can state that the difference in mean violence rate between states possessing gun control laws and states that do not possess gun control laws is not a zero value.


## Linear Regression

```{r}
#predicting violence rate based off income, male, and murder rate.
guns$c_income<-guns$income-mean(guns$income)
guns$c_male<-guns$male-mean(guns$male)
guns$c_murder<-guns$murder-mean(guns$murder)
fit<-lm(violent~c_income*c_male*c_murder,data=guns);summary(fit)
#Plotting linear regression
guns%>%ggplot(aes(c_income,violent))+
geom_point()+
geom_smooth(method='lm',se=F)
guns%>%ggplot(aes(c_male,violent))+
geom_point()+
geom_smooth(method='lm',se=F)
plot(guns$income,guns$violent)
plot(guns$male,guns$violent)
#homoskedasticity
library(lmtest)
bptest(fit)
resids<-fit$residuals
fitvals<-fit$fitted.values
#normality
ggplot()+
geom_point(aes(fitvals,resids))+
geom_hline(yintercept=0,color='green')

#Summary statistic
summary(fit)

#Accounting for standard errors
library(sandwich)
coeftest(fit,vcov=vcovHC(fit))

#Regression w/ no interaction
fit1<-lm(violent~c_income+c_male+c_murder,data=guns)

#Conduction ratio test
lrtest(fit1,fit)


```
Everytime income increases by 1, violence correspondingly increases by a factor of 3.105e-02. On the other hand, for every 1 unit increase in male percentage, it is followed by a -2.235e+01 unit increase in violence. Lastly, every time there is a one unit increase in the murder rate, there is a 5.213e+01 increase in the violence rate. The scatterplot between all of the variables show a generally linear pattern however there are some noticeable outlier patchces in the data. A BP test resulted in a p-value that is much smaller than 0.05. As a result, the test shows that heteroskedasticity does not exist in the data. Also, it can be seen that the histogram for residuals looks symetrical and appears to follow a normal distribution. Also because the sample size is very large, it appears the data is likely normal.The regression was run using robust standard errors. The results showed that the dependent variables are all statistically significant in being used to determine the violence rate since all of the p-values are below 0.05. 80.3% of the variation in violence rate can be explained by the percentage of males, income, and murder level based off the summary of the fit. Lastly, the  likelihood ratio test was conducted in the above code, there was a statistically significant improvement for the following predictor variables: males, income, and murder levels.

```{r}
#Bootstrap errors
samp_distn<-replicate(5000, {
boot_dat<-guns[sample(nrow(guns),replace=TRUE),]
fit2<-lm(violent~income*male*murder,data=boot_dat)
coef(fit2)
})
samp_distn%>%t%>%as.data.frame%>%summarize_all(sd)
```
The bootsrapped standard errors are much larger compared to both the original standard errors and the robust standard errors. They were larger for all of the individual variables:income, male, and murder levels. The bootstrapped standard error of the interaction between glucose and insulin was larger than both the original and robust standard errors. The bootstraped standard error for interaction between income:male, income:murder, and male:murder were also larger than the standard and robust errors. Because of the fact that the bootstrapped standard errors were all larger compared to the original and the robust standard errors, the p-values were also larger as a result which makes sense given the nature of standard errors.

## Logistic Regression
```{r}
#logistic regression to predict if there is a gun law 
guns$law<-ifelse(guns$law=="yes",1,0)
fit3<-glm(law~violent+male,data=guns,family=binomial(link="logit"));coeftest(fit3)
exp(-0.00304386)
exp(-0.54069065)
guns$prob<-predict(fit3,type = "response")
table(truth=guns$law,prediction=as.numeric(guns$prob>.5))%>%addmargins
#Accuracy
(838+88)/1173

#Sensitivity 
88/285

#Specificity
838/888

#Precision
88/138

#ROC Plot and AUC

tdat<-guns%>%mutate(prediction=ifelse(prob>0.5,1,0))
classify<-tdat%>%transmute(prob,prediction,truth=law)
library(plotROC)
ROCplot <- ggplot(guns) +geom_roc(aes(d=law, m=prob), n.cuts = 0) + geom_segment(aes(x=0, xend=1, y=0, yend=1))
ROCplot
calc_auc(ROCplot)

#Density plot
library(ggplot2)
guns$logit<-predict(fit3) #get predicted log-odds
guns$law<-as.factor(guns$law)
ggplot(guns,aes(logit, fill=law))+geom_density(alpha=.3)+
geom_vline(xintercept=0,lty=2)



#Creating function
class_diag<-function(probs,truth){
tab<-table(factor(probs>.5,levels=c("FALSE","TRUE")),truth)
acc=sum(diag(tab))/sum(tab)
sens=tab[2,2]/colSums(tab)[2]
spec=tab[1,1]/colSums(tab)[1]
ppv=tab[2,2]/rowSums(tab)[2]
if(is.numeric(truth)==FALSE & is.logical(truth)==FALSE) truth<-as.numeric(truth)-1
#Auc Calculation
ord<-order(probs, decreasing=TRUE)
probs <- probs[ord]; truth <- truth[ord]
TPR=cumsum(truth)/max(1,sum(truth))
FPR=cumsum(!truth)/max(1,sum(!truth))
dup<-c(probs[-1]>=probs[-length(probs)], FALSE)
TPR<-c(0,TPR[!dup],1); FPR<-c(0,FPR[!dup],1)
n <- length(TPR)
auc<- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )
data.frame(acc,sens,spec,ppv,auc)
}

#10-fold cross validation
set.seed(1234)
k=10
guns1<-guns%>%dplyr::select(-prob)
data1<-guns1[sample(nrow(guns1)),]
folds<-cut(seq(1:nrow(data1)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
## Training set
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$law
## Training model
fit3<-glm(law~violent+male,data=guns,family=binomial(link="logit"))
probs<-predict(fit3,newdata = test,type="response")
## Test model
diags<-rbind(diags,class_diag(probs,truth))
}
apply(diags,2,mean) 

```

Violent crime rate multiplies the odds of their being a gun law by 0.9969608 and every percent of males increasing in the population between the ages of 10 to 29 multiplies the odds of their being a gun law by 0.5823459. This means that there is actually a negative correlation between male percent and violent crime with the chance that there are gun laws. The accuracy of this model was found to be 78.9 percent, the sensitivity was found to be 30.9 percent, the specificity was found to be 94.3 percent, and the precision for the model was found to be 63.8 percent. The area under the ROC curve was .76. This means the model is somewhat decent at predicting whether or not a state has gun laws. A 10-cross validation test was performed. It showed that the out of sample accuracy was 78.9, sensitivity was 31.1, specificity was 94.4, and AUC was 76.6 percent.

## Lasso Regression
```{r}
#Lasso regression
library(glmnet)
guns2<-guns%>%dplyr::select(violent,murder,income,male,law)
y<-as.matrix(guns2$law)
x<-model.matrix(law~(.),data=guns2)[,-1]
cv<-cv.glmnet(x,y,family="binomial")
lasso<-glmnet(x,y,family="binomial",lambda=cv$lambda.1se)
coef(lasso)

set.seed(1234)
k=10
guns1<-guns%>%dplyr::select(-prob)
data1<-guns1[sample(nrow(guns1)),]
folds<-cut(seq(1:nrow(data1)),breaks=k,labels=F)
diags<-NULL
for(i in 1:k){
## Creating test
train<-data1[folds!=i,]
test<-data1[folds==i,]
truth<-test$law
## Training
fit4<-glm(law~violent+male+income,data=guns,family="binomial")
probs<-predict(fit4,newdata = test,type="response")
## Testing
diags<-rbind(diags,class_diag(probs,truth))
}
apply(diags,2,mean) #average across all k results
```

After the lasso regression was run on the data, only glucose, BMI, and age were shown to be important in determining if there was a gun control law. A 10-fold cross validation test with these variables was conducted. The accuracy of the
model increased very slightly to 79.7% in comparison to 78.9% which was based on a regression without including murder rate. It makes sense that the accuracy increased as one less factor has to be considered. The model's out of sample AUC was 77.3 percent which was also better than the AUC's of the logistic regressions above (76.6 percent).


...





